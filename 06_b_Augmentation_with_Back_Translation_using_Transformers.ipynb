{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" src=\"https://www.fhnw.ch/de/++theme++web16theme/assets/media/img/fachhochschule-nordwestschweiz-fhnw-logo.svg\" alt=\"FHNW Logo\">\n",
    "\n",
    "\n",
    "# Data Augmentation with Back Translation using Transformers\n",
    "\n",
    "by Fabian Märki\n",
    "\n",
    "## Summary\n",
    "The aim of this notebook is to show how Huggingface's model can be used for back translation.\n",
    "\n",
    "### Sources\n",
    "- [Text Data Augmentation with Back Translation](https://amitness.com/back-translation/)\n",
    "- [Faster batch translation](https://github.com/huggingface/transformers/issues/9994) with code example\n",
    "\n",
    "### Libraries/Models\n",
    "- [Hugging Face](https://huggingface.co)\n",
    "- [Translation Models](https://huggingface.co/models?language=de&pipeline_tag=translation&sort=downloads&search=Helsinki-NLP) that can be used with this code\n",
    "\n",
    "This notebook contains assigments: <font color='red'>Questions are written in red.</font>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/markif/2024_FS_CAS_NLP_LAB_Notebooks/blob/master/06_b_Augmentation_with_Back_Translation_using_Transformers.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install 'fhnw-nlp-utils>=0.8.0,<0.9.0'\n",
    "\n",
    "from fhnw.nlp.utils.processing import parallelize_dataframe\n",
    "from fhnw.nlp.utils.processing import is_iterable\n",
    "from fhnw.nlp.utils.storage import download\n",
    "from fhnw.nlp.utils.storage import save_dataframe\n",
    "from fhnw.nlp.utils.storage import load_dataframe\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure that a GPU is available (see [here](https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm))!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS name: posix\n",
      "Platform name: Linux\n",
      "Platform release: 5.13.0-41-generic\n",
      "Python version: 3.8.10\n",
      "CPU cores: 6\n",
      "RAM: 31.13GB total and 8.26GB available\n",
      "Tensorflow version: 2.8.0\n",
      "GPU is available\n",
      "GPU is a NVIDIA GeForce RTX 2070 with Max-Q Design with 8192MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 09:23:18.728932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-22 09:23:18.741672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-22 09:23:18.741858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from fhnw.nlp.utils.system import set_log_level\n",
    "from fhnw.nlp.utils.system import system_info\n",
    "\n",
    "set_log_level()\n",
    "print(system_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 2.55 s, total: 20.2 s\n",
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(357764, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "download(\"https://drive.switch.ch/index.php/s/0hE8wO4FbfGIJld/download\", \"data/german_doctor_reviews_tokenized.parq\")\n",
    "data = load_dataframe(\"data/german_doctor_reviews_tokenized.parq\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ich, bin, franzose, und, bin, seit, ein, paar...</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>[franzose, seit, paar, woche, muenchen, zahn, ...</td>\n",
       "      <td>[Ich, bin, franzose, und, bin, seit, ein, paar...</td>\n",
       "      <td>[Ich, bin, franzose, und, bin, seit, ein, paar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Dieser, Arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnen, unfr...</td>\n",
       "      <td>[Dieser, Arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>[Dieser, Arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[Hatte, akute, Beschwerden, am, Rücken, ., Her...</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken . Herr Magur...</td>\n",
       "      <td>[akut, beschwerde, rücken, herr, magura, erste...</td>\n",
       "      <td>[Hatte, akute, Beschwerden, am, Rücken, ., Her...</td>\n",
       "      <td>[Hatte, akute, Beschwerden, am, Rücken, ., Her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...     2.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...     1.0   \n",
       "\n",
       "                                                text     label  sentiment  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...  positive          1   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...  positive          1   \n",
       "\n",
       "                                         token_clean  \\\n",
       "0  [Ich, bin, franzose, und, bin, seit, ein, paar...   \n",
       "1  [Dieser, Arzt, ist, das, unmöglichste, was, mi...   \n",
       "2  [Hatte, akute, Beschwerden, am, Rücken, ., Her...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...   \n",
       "2  Hatte akute Beschwerden am Rücken . Herr Magur...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "0  [franzose, seit, paar, woche, muenchen, zahn, ...   \n",
       "1  [arzt, unmöglichste, leben, je, begegnen, unfr...   \n",
       "2  [akut, beschwerde, rücken, herr, magura, erste...   \n",
       "\n",
       "                                          token_stem  \\\n",
       "0  [Ich, bin, franzose, und, bin, seit, ein, paar...   \n",
       "1  [Dieser, Arzt, ist, das, unmöglichste, was, mi...   \n",
       "2  [Hatte, akute, Beschwerden, am, Rücken, ., Her...   \n",
       "\n",
       "                               token_clean_stopwords  \n",
       "0  [Ich, bin, franzose, und, bin, seit, ein, paar...  \n",
       "1  [Dieser, Arzt, ist, das, unmöglichste, was, mi...  \n",
       "2  [Hatte, akute, Beschwerden, am, Rücken, ., Her...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the computed columns (will need to be re-computed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"token_clean\", \"token_lemma\", \"token_stem\", \"token_clean_stopwords\", \"text_clean\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...     2.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...     1.0   \n",
       "\n",
       "                                                text     label  sentiment  \n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...  positive          1  \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1  \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...  positive          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep negative text (the class with fewer samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33025, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augm = data[data[\"label\"] == \"negative\"]\n",
    "data_augm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1. Termin:&lt;br /&gt;\\n1 Stunde Wartezimmer + 2 min...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1. Termin:&lt;br /&gt;\\n1 Stunde Wartezimmer + 2 min...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Eine sehr unfreundliche Ärztin, so etwas habe ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Eine sehr unfreundliche Ärztin, so etwas habe ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_original  rating  \\\n",
       "1   Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "13  1. Termin:<br />\\n1 Stunde Wartezimmer + 2 min...     6.0   \n",
       "19  Eine sehr unfreundliche Ärztin, so etwas habe ...     6.0   \n",
       "\n",
       "                                                 text     label  sentiment  \n",
       "1   Dieser Arzt ist das unmöglichste was mir in me...  negative         -1  \n",
       "13  1. Termin:<br />\\n1 Stunde Wartezimmer + 2 min...  negative         -1  \n",
       "19  Eine sehr unfreundliche Ärztin, so etwas habe ...  negative         -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_augm = data_augm.reset_index(drop=True)\n",
    "data_augm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install torch transformers sentencepiece mosestokenizer sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_empty_cache():\n",
    "    \"\"\"Cleans the GPU cache which seems to fill up after a while\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    import torch\n",
    "    import tensorflow as tf\n",
    "\n",
    "    if tf.config.list_physical_devices(\"GPU\"):\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "def get_gpu_device_number():\n",
    "    \"\"\"Provides the number of the GPU device\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The GPU device number of -1 if none is installed\n",
    "    \"\"\"\n",
    "        \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    return 0 if tf.config.list_physical_devices(\"GPU\") else -1\n",
    "\n",
    "def get_compute_device():\n",
    "    \"\"\"Provides the device for the computation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The GPU device with number (cuda:0) of cpu\n",
    "    \"\"\"\n",
    "        \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    return \"cuda:0\" if tf.config.list_physical_devices(\"GPU\") else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Translation\n",
    "\n",
    "You might repeate following steps for several languages (see [here](https://huggingface.co/models?language=de&pipeline_tag=translation&sort=downloads&search=Helsinki-NLP) for alternative models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Try a different language by replacing `lang_to` with another from the [Helsinki-NLP/opus-mt-...](https://huggingface.co/models?language=de&pipeline_tag=translation&sort=downloads&search=Helsinki-NLP) list.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2a35eda174409d93dffebd7a6f88c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a186653e754f558c699bd113d0c746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/799k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f973e98db974c4a9aab616ab0bd53d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c3585d98fa4b58b21f86b0c513b03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db598c84c25a4ab99691251d5992cfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5015931cb2c14264b513bc4519d4e589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90937988722b4410bce3f83b69b84fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/799k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a2cf8441274379928f9fdd3ab27cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a2e6e51b68481491a925bd4f99e8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d6bf7b2405476e9a946f344375df8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8070f92049a642bd84dc0283b16457df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c146a4b565459f8d19d6b48d8979c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace values to load different tranlsation models\n",
    "lang_from = \"de\"\n",
    "lang_to = \"es\"\n",
    "compute_device = get_compute_device()\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "orig2dest_model_name = \"Helsinki-NLP/opus-mt-\"+lang_from+\"-\"+lang_to\n",
    "orig2dest_tokenizer = MarianTokenizer.from_pretrained(orig2dest_model_name)\n",
    "orig2dest_model = MarianMTModel.from_pretrained(orig2dest_model_name).to(compute_device)\n",
    "dest2orig_model_name = \"Helsinki-NLP/opus-mt-\"+lang_to+\"-\"+lang_from\n",
    "dest2orig_tokenizer = MarianTokenizer.from_pretrained(dest2orig_model_name)\n",
    "dest2orig_model = MarianMTModel.from_pretrained(dest2orig_model_name).to(compute_device)\n",
    "\n",
    "#from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "#orig2dest_model_name = \"facebook/wmt19-\"+lang_from+\"-\"+lang_to\n",
    "#orig2dest_tokenizer = FSMTTokenizer.from_pretrained(orig2dest_model_name)\n",
    "#orig2dest_model = FSMTForConditionalGeneration.from_pretrained(orig2dest_model_name).to(device)\n",
    "#dest2orig_model_name = \"facebook/wmt19-\"+lang_to+\"-\"+lang_from\n",
    "#dest2orig_tokenizer = FSMTTokenizer.from_pretrained(dest2orig_model_name)\n",
    "#dest2orig_model = FSMTForConditionalGeneration.from_pretrained(dest2orig_model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Print the intermediate translations (i.e. decode the `tokenized_dest_texts`) in order to get an understanding of the *creative power* of the back translation (you might want to choose a language you understand).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate_transformers(texts):\n",
    "    #tokenized_texts = orig2dest_tokenizer.prepare_seq2seq_batch(texts, return_tensors=\"pt\").to(compute_device)\n",
    "    tokenized_texts = orig2dest_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(compute_device)\n",
    "    back_translations = [set() for _ in range(len(texts))]\n",
    "\n",
    "    # Translate texts to target language (e.g. Spanish) and back to source language (e.g. German)\n",
    "    generate_kwargs = {\"num_beams\": 1, \"do_sample\": True, \"num_return_sequences\": 2}\n",
    "    tokenized_dest_texts = orig2dest_model.generate(tokenized_texts[\"input_ids\"], attention_mask=tokenized_texts[\"attention_mask\"], top_p=0.7, **generate_kwargs)\n",
    "    tokenized_source_texts = dest2orig_model.generate(tokenized_dest_texts, top_p=0.8, **generate_kwargs)\n",
    "    \n",
    "    # TODO: !!! place your code here !!!\n",
    "    ####################################\n",
    "\n",
    "        \n",
    "    ###################\n",
    "    # TODO: !!! end !!!\n",
    "\n",
    "    # Decode and deduplicate back-translations and assign to original text indices\n",
    "    for i, t in enumerate(tokenized_source_texts):\n",
    "        back_translations[i // 4].add(dest2orig_tokenizer.decode(t, skip_special_tokens=True).lower())\n",
    "\n",
    "    # Remove back translations that are empty or equal to the original text\n",
    "    return [[bt for bt in s if bt and bt != t] for s, t in zip(back_translations, map(str.lower, texts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it a try..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hey alle zusammen. wie geht es euch heute?',\n",
       "  'wie geht es euch heute?',\n",
       "  \"wie geht's euch heute?\",\n",
       "  \"hallo zusammen. wie geht's euch?\"],\n",
       " ['das ist doch nicht schön!',\n",
       "  'die nep ist wundervoll, oder?',\n",
       "  'nup ist cool, oder?',\n",
       "  'die nlp ist cool, oder?']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translate_transformers([\"Hallo zusammen! Wie geht es euch heute?\", \"NLP ist grossartig, oder?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual back translation. Following code allows for recovery in case of a crash..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:57:15.177100 save  9 200\n",
      "18:58:04.230533 save  19 400\n",
      "18:58:46.593890 save  29 600\n",
      "18:59:20.396303 save  39 800\n",
      "19:00:10.148870 save  49 1000\n",
      "19:00:48.643269 save  59 1199\n",
      "19:01:34.019750 save  69 1399\n",
      "19:02:09.695394 save  79 1599\n",
      "19:02:53.011411 save  89 1799\n",
      "19:03:44.463772 save  99 1999\n",
      "19:04:28.071842 save  109 2198\n",
      "19:05:11.483798 save  119 2394\n",
      "19:05:50.864190 save  129 2593\n",
      "19:06:38.129842 save  139 2793\n",
      "19:07:18.620444 save  149 2992\n",
      "19:08:07.999118 save  159 3190\n",
      "19:08:45.273486 save  169 3390\n",
      "19:09:29.834619 save  179 3590\n",
      "19:10:11.951686 save  189 3789\n",
      "19:10:53.533496 save  199 3989\n",
      "19:11:42.275821 save  209 4189\n",
      "19:12:28.124029 save  219 4388\n",
      "19:13:19.708618 save  229 4588\n",
      "19:14:09.213708 save  239 4788\n",
      "19:14:48.271840 save  249 4988\n",
      "19:15:31.502111 save  259 5188\n",
      "19:16:21.794479 save  269 5388\n",
      "19:17:04.767862 save  279 5587\n",
      "19:18:00.978876 save  289 5785\n",
      "19:18:48.882123 save  299 5983\n",
      "19:19:28.317660 save  309 6183\n",
      "19:20:11.833771 save  319 6383\n",
      "19:20:50.492828 save  329 6583\n",
      "19:21:30.216783 save  339 6782\n",
      "19:22:16.168583 save  349 6982\n",
      "19:23:04.719602 save  359 7181\n",
      "19:23:49.609117 save  369 7380\n",
      "19:24:28.819566 save  379 7578\n",
      "19:25:14.924938 save  389 7778\n",
      "19:26:03.371400 save  399 7978\n",
      "19:26:51.327456 save  409 8177\n",
      "19:27:38.171688 save  419 8377\n",
      "19:28:28.111907 save  429 8577\n",
      "19:29:10.897578 save  439 8777\n",
      "19:29:57.858981 save  449 8977\n",
      "19:30:40.313843 save  459 9175\n",
      "19:31:27.013340 save  469 9373\n",
      "19:32:08.425291 save  479 9573\n",
      "19:32:50.948473 save  489 9773\n",
      "19:33:40.703325 save  499 9973\n",
      "19:34:27.566998 save  509 10173\n",
      "19:35:08.890319 save  519 10371\n",
      "19:35:52.889612 save  529 10571\n",
      "19:36:40.037615 save  539 10770\n",
      "19:37:20.284497 save  549 10969\n",
      "19:38:09.325527 save  559 11169\n",
      "19:38:54.540545 save  569 11369\n",
      "19:39:35.675473 save  579 11566\n",
      "19:40:20.792283 save  589 11766\n",
      "19:41:10.320119 save  599 11966\n",
      "19:41:58.238470 save  609 12165\n",
      "19:42:54.549175 save  619 12365\n",
      "19:43:56.018403 save  629 12563\n",
      "19:44:38.984472 save  639 12763\n",
      "19:45:23.832364 save  649 12962\n",
      "19:46:07.195152 save  659 13161\n",
      "19:46:52.602952 save  669 13361\n",
      "19:47:38.201329 save  679 13560\n",
      "19:48:20.459069 save  689 13760\n",
      "19:48:59.368185 save  699 13960\n",
      "19:49:44.598903 save  709 14160\n",
      "19:50:32.426898 save  719 14360\n",
      "19:51:16.828776 save  729 14560\n",
      "19:52:10.009990 save  739 14759\n",
      "19:52:53.169115 save  749 14952\n",
      "19:53:40.932914 save  759 15152\n",
      "19:54:19.883366 save  769 15350\n",
      "19:55:03.944315 save  779 15549\n",
      "19:55:49.293393 save  789 15749\n",
      "19:56:39.377529 save  799 15949\n",
      "19:57:24.640820 save  809 16149\n",
      "19:58:18.261680 save  819 16348\n",
      "19:58:57.068612 save  829 16548\n",
      "19:59:47.107835 save  839 16744\n",
      "20:00:36.559470 save  849 16944\n",
      "20:01:23.760389 save  859 17144\n",
      "20:02:07.281463 save  869 17344\n",
      "20:02:57.277071 save  879 17544\n",
      "20:03:38.315179 save  889 17743\n",
      "20:04:29.842852 save  899 17943\n",
      "20:05:19.168770 save  909 18142\n",
      "20:06:07.209970 save  919 18342\n",
      "20:06:50.543203 save  929 18540\n",
      "20:07:39.927229 save  939 18740\n",
      "20:08:32.621277 save  949 18937\n",
      "20:09:20.565274 save  959 19136\n",
      "20:10:06.740815 save  969 19336\n",
      "20:10:51.343907 save  979 19533\n",
      "20:11:41.610372 save  989 19733\n",
      "20:12:34.839466 save  999 19932\n",
      "20:13:25.361353 save  1009 20132\n",
      "20:14:21.795473 save  1019 20332\n",
      "20:15:08.260291 save  1029 20532\n",
      "20:15:58.616863 save  1039 20731\n",
      "20:16:38.774115 save  1049 20930\n",
      "20:17:35.719413 save  1059 21129\n",
      "20:18:26.512891 save  1069 21329\n",
      "20:19:24.716998 save  1079 21527\n",
      "20:20:13.061571 save  1089 21724\n",
      "20:21:04.332048 save  1099 21921\n",
      "20:21:51.736956 save  1109 22121\n",
      "20:22:37.906612 save  1119 22320\n",
      "20:23:19.162619 save  1129 22520\n",
      "20:24:09.934858 save  1139 22720\n",
      "20:24:48.296621 save  1149 22917\n",
      "20:25:33.473044 save  1159 23116\n",
      "20:26:20.493807 save  1169 23316\n",
      "20:27:16.354934 save  1179 23516\n",
      "20:28:14.592681 save  1189 23715\n",
      "20:28:57.066389 save  1199 23911\n",
      "20:29:45.734795 save  1209 24109\n",
      "20:30:35.232243 save  1219 24309\n",
      "20:31:22.149920 save  1229 24509\n",
      "20:32:11.272632 save  1239 24709\n",
      "20:32:59.310407 save  1249 24908\n",
      "20:33:48.693334 save  1259 25106\n",
      "20:34:30.758145 save  1269 25306\n",
      "20:35:18.490486 save  1279 25506\n",
      "20:36:01.718107 save  1289 25705\n",
      "20:36:57.930997 save  1299 25904\n",
      "20:37:40.938961 save  1309 26098\n",
      "20:38:27.153029 save  1319 26295\n",
      "20:39:16.908594 save  1329 26495\n",
      "20:39:59.957040 save  1339 26695\n",
      "20:40:47.609452 save  1349 26895\n",
      "20:41:35.264386 save  1359 27095\n",
      "20:42:28.278429 save  1369 27295\n",
      "20:43:11.627829 save  1379 27495\n",
      "20:43:55.945587 save  1389 27695\n",
      "20:44:47.605023 save  1399 27895\n",
      "20:45:33.427179 save  1409 28094\n",
      "20:46:19.846148 save  1419 28294\n",
      "20:47:07.390192 save  1429 28494\n",
      "20:47:50.926955 save  1439 28694\n",
      "20:48:37.782520 save  1449 28893\n",
      "20:49:28.788223 save  1459 29093\n",
      "20:50:17.016523 save  1469 29293\n",
      "20:50:56.895854 save  1479 29493\n",
      "20:51:44.675686 save  1489 29693\n",
      "20:52:31.437929 save  1499 29893\n",
      "20:53:22.110667 save  1509 30092\n",
      "20:54:07.034759 save  1519 30292\n",
      "20:54:47.158014 save  1529 30491\n",
      "20:55:40.095505 save  1539 30691\n",
      "20:56:30.255172 save  1549 30891\n",
      "20:57:12.337923 save  1559 31090\n",
      "20:57:57.265299 save  1569 31289\n",
      "20:58:41.991360 save  1579 31489\n",
      "20:59:29.966758 save  1589 31688\n",
      "21:00:12.142011 save  1599 31888\n",
      "21:01:02.490430 save  1609 32088\n",
      "21:01:49.995818 save  1619 32287\n",
      "21:02:34.010197 save  1629 32486\n",
      "21:03:13.807974 save  1639 32686\n",
      "21:04:01.316739 save  1649 32885\n",
      "21:04:49.207917 save  1659 33083\n",
      "21:05:34.508447 save  1669 33281\n",
      "21:06:19.677786 save  1679 33481\n",
      "21:07:12.543289 save  1689 33680\n",
      "21:08:03.079150 save  1699 33879\n",
      "21:08:45.644325 save  1709 34079\n",
      "21:09:27.739280 save  1719 34279\n",
      "21:10:12.328242 save  1729 34479\n",
      "21:10:54.733354 save  1739 34676\n",
      "21:11:36.745702 save  1749 34875\n",
      "21:12:31.530903 save  1759 35075\n",
      "21:13:14.424516 save  1769 35272\n",
      "21:14:06.308289 save  1779 35472\n",
      "21:14:50.224792 save  1789 35672\n",
      "21:15:32.093727 save  1799 35872\n",
      "21:16:20.915387 save  1809 36072\n",
      "21:17:06.201797 save  1819 36272\n",
      "21:17:50.606771 save  1829 36472\n",
      "21:18:36.198432 save  1839 36672\n",
      "21:19:21.441018 save  1849 36871\n",
      "21:20:12.758084 save  1859 37071\n",
      "21:21:05.518081 save  1869 37271\n",
      "21:21:48.242843 save  1879 37471\n",
      "21:22:27.938546 save  1889 37668\n",
      "21:23:16.243915 save  1899 37868\n",
      "21:24:02.033062 save  1909 38067\n",
      "21:24:52.211478 save  1919 38266\n",
      "21:25:37.531470 save  1929 38466\n",
      "21:26:22.667917 save  1939 38666\n",
      "21:27:08.878538 save  1949 38865\n",
      "21:27:54.662089 save  1959 39064\n",
      "21:28:46.804503 save  1969 39260\n",
      "21:29:43.950304 save  1979 39458\n",
      "21:30:26.211171 save  1989 39658\n",
      "21:31:05.402862 save  1999 39858\n",
      "21:31:52.684131 save  2009 40058\n",
      "21:32:33.809466 save  2019 40257\n",
      "21:33:24.257828 save  2029 40456\n",
      "21:34:15.597282 save  2039 40655\n",
      "21:34:58.328364 save  2049 40854\n",
      "21:35:47.046154 save  2059 41053\n",
      "21:36:31.923814 save  2069 41252\n",
      "21:37:18.585391 save  2079 41450\n",
      "21:38:20.134942 save  2089 41650\n",
      "21:39:02.002624 save  2099 41849\n",
      "21:39:47.529168 save  2109 42048\n",
      "21:40:22.771950 save  2119 42247\n",
      "21:41:03.748774 save  2129 42447\n",
      "21:41:43.607987 save  2139 42647\n",
      "21:42:31.111828 save  2149 42846\n",
      "21:43:09.329624 save  2159 43046\n",
      "21:44:01.470963 save  2169 43246\n",
      "21:44:51.148161 save  2179 43446\n",
      "21:45:34.794999 save  2189 43645\n",
      "21:46:15.366505 save  2199 43845\n",
      "21:46:57.221644 save  2209 44045\n",
      "21:47:41.323521 save  2219 44244\n",
      "21:48:22.573736 save  2229 44444\n",
      "21:49:08.902634 save  2239 44643\n",
      "21:49:56.116631 save  2249 44843\n",
      "21:50:36.275777 save  2259 45042\n",
      "21:51:22.474665 save  2269 45242\n",
      "21:52:11.954882 save  2279 45442\n",
      "21:52:51.271101 save  2289 45641\n",
      "21:53:25.727099 save  2299 45839\n",
      "21:54:08.320509 save  2309 46039\n",
      "21:54:47.804243 save  2319 46239\n",
      "21:55:33.066412 save  2329 46439\n",
      "21:56:17.655516 save  2339 46637\n",
      "21:57:02.654254 save  2349 46837\n",
      "21:57:50.995003 save  2359 47035\n",
      "21:58:36.319302 save  2369 47235\n",
      "21:59:26.219143 save  2379 47435\n",
      "22:00:06.732476 save  2389 47635\n",
      "22:00:44.728594 save  2399 47835\n",
      "22:01:31.296701 save  2409 48032\n",
      "22:02:13.619835 save  2419 48232\n",
      "22:02:57.902345 save  2429 48432\n",
      "22:03:41.410219 save  2439 48632\n",
      "22:04:26.324058 save  2449 48832\n",
      "22:05:10.366733 save  2459 49032\n",
      "22:05:56.864883 save  2469 49232\n",
      "22:06:37.603928 save  2479 49432\n",
      "22:07:21.896570 save  2489 49629\n",
      "22:08:00.327322 save  2499 49829\n",
      "22:08:52.064691 save  2509 50028\n",
      "22:09:36.267889 save  2519 50228\n",
      "22:10:22.300825 save  2529 50427\n",
      "22:11:09.483665 save  2539 50627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:11:49.525445 save  2549 50826\n",
      "22:12:29.796671 save  2559 51025\n",
      "22:13:15.541371 save  2569 51225\n",
      "22:13:54.572111 save  2579 51423\n",
      "22:14:39.089773 save  2589 51621\n",
      "22:15:20.697976 save  2599 51821\n",
      "22:16:00.220314 save  2609 52020\n",
      "22:16:44.523383 save  2619 52220\n",
      "22:17:26.719839 save  2629 52419\n",
      "22:18:03.256933 save  2639 52619\n",
      "22:18:40.635427 save  2649 52819\n",
      "22:19:19.992430 save  2659 53019\n",
      "22:20:02.096301 save  2669 53219\n",
      "22:20:42.832027 save  2679 53419\n",
      "22:21:35.766685 save  2689 53619\n",
      "22:22:21.436371 save  2699 53819\n",
      "22:23:13.914345 save  2709 54019\n",
      "22:23:59.287376 save  2719 54219\n",
      "22:24:43.714659 save  2729 54419\n",
      "22:25:32.439938 save  2739 54619\n",
      "22:26:15.180007 save  2749 54817\n",
      "22:27:01.880496 save  2759 55017\n",
      "22:27:37.211876 save  2769 55217\n",
      "22:28:35.122129 save  2779 55414\n",
      "22:29:14.512137 save  2789 55614\n",
      "22:29:59.110689 save  2799 55814\n",
      "22:30:42.627662 save  2809 56014\n",
      "22:31:27.409720 save  2819 56212\n",
      "22:32:04.954329 save  2829 56410\n",
      "22:32:49.213655 save  2839 56610\n",
      "22:33:37.619490 save  2849 56810\n",
      "22:34:15.357589 save  2859 57010\n",
      "22:35:00.314935 save  2869 57210\n",
      "22:35:46.130738 save  2879 57408\n",
      "22:36:29.392488 save  2889 57608\n",
      "22:37:19.990399 save  2899 57807\n",
      "22:38:05.667830 save  2909 58007\n",
      "22:38:47.578982 save  2919 58207\n",
      "22:39:25.328907 save  2929 58406\n",
      "22:40:04.593394 save  2939 58606\n",
      "22:40:47.978334 save  2949 58805\n",
      "22:41:20.940784 save  2959 59005\n",
      "22:41:54.676531 save  2969 59204\n",
      "22:42:30.437141 save  2979 59404\n",
      "22:43:09.783711 save  2989 59604\n",
      "22:43:47.086668 save  2999 59804\n",
      "22:44:29.812944 save  3009 60003\n",
      "22:45:13.253365 save  3019 60202\n",
      "22:45:53.876994 save  3029 60400\n",
      "22:46:40.935588 save  3039 60600\n",
      "22:47:21.618512 save  3049 60800\n",
      "22:48:07.271363 save  3059 61000\n",
      "22:48:50.973120 save  3069 61200\n",
      "22:49:34.694838 save  3079 61400\n",
      "22:50:19.777538 save  3089 61599\n",
      "22:51:16.585613 save  3099 61799\n",
      "22:52:05.442618 save  3109 61999\n",
      "22:52:43.727761 save  3119 62196\n",
      "22:53:25.800309 save  3129 62396\n",
      "22:54:08.260228 save  3139 62595\n",
      "22:54:49.725558 save  3149 62793\n",
      "22:55:32.235401 save  3159 62992\n",
      "22:56:11.570942 save  3169 63189\n",
      "22:56:54.379862 save  3179 63388\n",
      "22:57:42.569546 save  3189 63588\n",
      "22:58:26.135001 save  3199 63788\n",
      "22:59:07.051312 save  3209 63988\n",
      "22:59:49.057706 save  3219 64188\n",
      "23:00:38.971729 save  3229 64388\n",
      "23:01:23.273532 save  3239 64588\n",
      "23:02:04.015925 save  3249 64788\n",
      "23:02:50.900626 save  3259 64988\n",
      "23:03:31.897802 save  3269 65188\n",
      "23:04:15.090903 save  3279 65387\n",
      "23:04:57.871702 save  3289 65585\n",
      "23:05:40.985319 save  3299 65785\n",
      "23:06:19.954750 save  3309 65985\n",
      "23:07:03.458788 save  3319 66184\n",
      "23:07:47.481355 save  3329 66384\n",
      "23:08:31.829734 save  3339 66582\n",
      "23:09:14.261477 save  3349 66782\n",
      "23:10:08.791688 save  3359 66982\n",
      "23:10:52.748221 save  3369 67182\n",
      "23:11:32.401362 save  3379 67380\n",
      "23:12:10.349327 save  3389 67580\n",
      "23:12:58.831429 save  3399 67779\n",
      "23:13:36.370565 save  3409 67979\n",
      "23:14:28.823843 save  3419 68178\n",
      "23:15:10.264577 save  3429 68377\n",
      "23:15:43.257507 save  3439 68576\n",
      "23:16:26.728514 save  3449 68775\n",
      "23:17:10.743535 save  3459 68975\n",
      "23:17:45.845607 save  3469 69175\n",
      "23:18:30.554582 save  3479 69374\n",
      "23:19:18.131934 save  3489 69574\n",
      "23:19:58.369222 save  3499 69774\n",
      "23:20:35.635499 save  3509 69974\n",
      "23:21:13.709552 save  3519 70173\n",
      "23:22:06.222244 save  3529 70373\n",
      "23:22:51.503543 save  3539 70573\n",
      "23:23:29.033152 save  3549 70770\n",
      "23:24:05.942439 save  3559 70969\n",
      "23:24:43.645164 save  3569 71168\n",
      "23:25:29.560599 save  3579 71368\n",
      "23:26:18.644912 save  3589 71568\n",
      "23:26:58.710434 save  3599 71767\n",
      "23:27:37.117768 save  3609 71967\n",
      "23:28:19.299605 save  3619 72167\n",
      "23:28:56.582946 save  3629 72367\n",
      "23:29:33.025371 save  3639 72567\n",
      "23:30:11.277238 save  3649 72764\n",
      "23:30:51.174134 save  3659 72964\n",
      "23:31:33.094450 save  3669 73164\n",
      "23:32:14.797266 save  3679 73364\n",
      "23:32:56.901980 save  3689 73563\n",
      "23:33:37.834829 save  3699 73762\n",
      "23:34:15.752893 save  3709 73962\n",
      "23:34:57.048001 save  3719 74162\n",
      "23:35:36.071590 save  3729 74362\n",
      "23:36:15.072157 save  3739 74557\n",
      "23:36:53.574715 save  3749 74757\n",
      "23:37:34.324775 save  3759 74957\n",
      "23:38:08.984160 save  3769 75156\n",
      "23:38:43.619807 save  3779 75353\n",
      "23:39:24.682397 save  3789 75553\n",
      "23:39:59.293854 save  3799 75751\n",
      "23:40:41.173191 save  3809 75951\n",
      "23:41:16.808934 save  3819 76151\n",
      "23:41:58.608104 save  3829 76350\n",
      "23:42:44.683099 save  3839 76548\n",
      "23:43:22.885412 save  3849 76748\n",
      "23:44:05.122890 save  3859 76948\n",
      "23:44:44.711325 save  3869 77148\n",
      "23:45:21.153914 save  3879 77348\n",
      "23:46:02.672360 save  3889 77548\n",
      "23:46:49.891781 save  3899 77746\n",
      "23:47:25.369717 save  3909 77946\n",
      "23:48:00.438780 save  3919 78145\n",
      "23:48:42.973856 save  3929 78344\n",
      "23:49:26.913457 save  3939 78543\n",
      "23:50:13.879357 save  3949 78743\n",
      "23:50:57.908837 save  3959 78943\n",
      "23:51:40.162507 save  3969 79137\n",
      "23:52:25.175041 save  3979 79337\n",
      "23:53:13.146857 save  3989 79537\n",
      "23:53:54.848079 save  3999 79737\n",
      "23:54:36.317020 save  4009 79937\n",
      "23:55:22.665370 save  4019 80133\n",
      "23:56:00.794467 save  4029 80333\n",
      "23:56:40.987316 save  4039 80533\n",
      "23:57:25.151680 save  4049 80730\n",
      "23:58:11.306455 save  4059 80928\n",
      "23:59:01.970050 save  4069 81125\n",
      "23:59:39.375256 save  4079 81325\n",
      "00:00:18.353464 save  4089 81524\n",
      "00:00:52.486784 save  4099 81724\n",
      "00:01:37.231702 save  4109 81924\n",
      "00:02:16.656228 save  4119 82124\n",
      "00:03:04.352795 save  4129 82324\n",
      "00:03:48.953169 save  4139 82524\n",
      "00:04:41.702070 save  4149 82723\n",
      "00:05:24.323446 save  4159 82923\n",
      "00:06:08.508409 save  4169 83123\n",
      "00:06:56.285300 save  4179 83323\n",
      "00:07:33.409703 save  4189 83522\n",
      "00:08:16.811461 save  4199 83722\n",
      "00:08:47.128085 save  4209 83919\n",
      "00:09:31.361510 save  4219 84119\n",
      "00:10:12.835888 save  4229 84319\n",
      "00:10:55.648108 save  4239 84519\n",
      "00:11:36.233651 save  4249 84718\n",
      "00:12:16.703460 save  4259 84918\n",
      "00:13:01.875859 save  4269 85116\n",
      "00:13:36.541900 save  4279 85314\n",
      "00:14:19.270697 save  4289 85514\n",
      "00:14:59.853386 save  4299 85714\n",
      "00:15:35.949823 save  4309 85911\n",
      "00:16:16.668644 save  4319 86111\n",
      "00:16:58.324086 save  4329 86311\n",
      "00:17:37.612786 save  4339 86511\n",
      "00:18:17.381174 save  4349 86710\n",
      "00:18:57.600939 save  4359 86910\n",
      "00:19:34.233495 save  4369 87110\n",
      "00:20:14.773299 save  4379 87308\n",
      "00:20:59.928108 save  4389 87508\n",
      "00:21:38.880140 save  4399 87708\n",
      "00:22:31.846560 save  4409 87907\n",
      "00:23:13.663693 save  4419 88107\n",
      "00:23:53.496800 save  4429 88307\n",
      "00:24:40.838227 save  4439 88507\n",
      "00:25:20.874040 save  4449 88707\n",
      "00:26:07.916821 save  4459 88907\n",
      "00:26:46.421895 save  4469 89106\n",
      "00:27:26.338998 save  4479 89305\n",
      "00:28:11.009651 save  4489 89503\n",
      "00:28:52.154513 save  4499 89702\n",
      "00:29:36.146415 save  4509 89902\n",
      "00:30:10.799992 save  4519 90102\n",
      "00:30:51.281537 save  4529 90302\n",
      "00:31:40.977070 save  4539 90502\n",
      "00:32:19.633552 save  4549 90702\n",
      "00:33:06.243135 save  4559 90902\n",
      "00:33:50.238457 save  4569 91102\n",
      "00:34:26.875330 save  4579 91302\n",
      "00:35:06.385086 save  4589 91502\n",
      "00:35:53.398111 save  4599 91702\n",
      "00:36:38.049560 save  4609 91902\n",
      "00:37:16.241703 save  4619 92102\n",
      "00:37:51.841363 save  4629 92302\n",
      "00:38:37.406148 save  4639 92502\n",
      "00:39:22.451627 save  4649 92702\n",
      "00:40:03.239917 save  4659 92902\n",
      "00:40:41.905096 save  4669 93102\n",
      "00:41:32.356984 save  4679 93302\n",
      "00:42:15.527819 save  4689 93502\n",
      "00:42:59.426697 save  4699 93699\n",
      "00:43:43.880964 save  4709 93899\n",
      "00:44:21.523268 save  4719 94099\n",
      "00:45:03.034708 save  4729 94299\n",
      "00:45:48.604667 save  4739 94499\n",
      "00:46:30.084880 save  4749 94698\n",
      "00:47:13.180984 save  4759 94898\n",
      "00:47:59.862813 save  4769 95098\n",
      "00:48:43.003129 save  4779 95298\n",
      "00:49:36.349343 save  4789 95498\n",
      "00:50:25.534117 save  4799 95698\n",
      "00:51:02.458305 save  4809 95898\n",
      "00:51:49.177653 save  4819 96098\n",
      "00:52:24.884099 save  4829 96298\n",
      "00:53:00.906642 save  4839 96498\n",
      "00:53:49.187184 save  4849 96697\n",
      "00:54:42.755525 save  4859 96894\n",
      "00:55:17.216806 save  4869 97093\n",
      "00:56:06.788947 save  4879 97291\n",
      "00:56:39.447040 save  4889 97490\n",
      "00:57:15.711899 save  4899 97689\n",
      "00:57:58.859716 save  4909 97889\n",
      "00:58:39.757508 save  4919 98089\n",
      "00:59:16.010830 save  4929 98288\n",
      "01:00:01.732871 save  4939 98488\n",
      "01:00:41.979580 save  4949 98687\n",
      "01:01:17.533167 save  4959 98886\n",
      "01:01:55.230835 save  4969 99086\n",
      "01:02:43.556882 save  4979 99285\n",
      "01:03:28.956212 save  4989 99484\n",
      "01:04:09.689153 save  4999 99684\n",
      "01:04:54.179519 save  5009 99884\n",
      "01:05:36.273638 save  5019 100084\n",
      "01:06:13.584586 save  5029 100283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:06:56.989071 save  5039 100483\n",
      "01:07:43.256454 save  5049 100682\n",
      "01:08:31.743081 save  5059 100879\n",
      "01:09:12.694339 save  5069 101078\n",
      "01:09:56.512193 save  5079 101276\n",
      "01:10:42.846280 save  5089 101476\n",
      "01:11:23.160982 save  5099 101676\n",
      "01:12:20.411902 save  5109 101875\n",
      "01:13:07.858737 save  5119 102074\n",
      "01:13:48.061761 save  5129 102273\n",
      "01:14:33.994112 save  5139 102471\n",
      "01:15:26.849796 save  5149 102670\n",
      "01:16:11.609486 save  5159 102870\n",
      "01:16:52.696900 save  5169 103069\n",
      "01:17:37.660609 save  5179 103269\n",
      "01:18:20.135089 save  5189 103469\n",
      "01:19:05.645657 save  5199 103669\n",
      "01:19:48.423901 save  5209 103868\n",
      "01:20:23.757046 save  5219 104068\n",
      "01:21:13.804059 save  5229 104268\n",
      "01:22:00.727248 save  5239 104467\n",
      "01:22:56.038267 save  5249 104664\n",
      "01:23:34.362813 save  5259 104864\n",
      "01:24:14.555954 save  5269 105064\n",
      "01:25:10.058400 save  5279 105262\n",
      "01:26:00.685083 save  5289 105462\n",
      "01:26:42.198247 save  5299 105661\n",
      "01:27:24.379479 save  5309 105861\n",
      "01:28:08.903399 save  5319 106060\n",
      "01:28:51.486324 save  5329 106260\n",
      "01:29:34.620968 save  5339 106460\n",
      "01:30:15.812666 save  5349 106660\n",
      "01:31:05.028602 save  5359 106860\n",
      "01:31:53.755044 save  5369 107060\n",
      "01:32:45.434313 save  5379 107260\n",
      "01:33:25.845115 save  5389 107460\n",
      "01:34:10.358271 save  5399 107660\n",
      "01:34:53.674906 save  5409 107860\n",
      "01:35:37.594269 save  5419 108060\n",
      "01:36:17.678387 save  5429 108260\n",
      "01:37:09.329649 save  5439 108459\n",
      "01:37:48.176017 save  5449 108658\n",
      "01:38:33.935194 save  5459 108858\n",
      "01:39:03.510337 save  5469 109058\n",
      "01:39:43.937672 save  5479 109258\n",
      "01:40:26.139603 save  5489 109458\n",
      "01:41:10.853705 save  5499 109654\n",
      "01:41:57.630312 save  5509 109853\n",
      "01:42:44.411219 save  5519 110053\n",
      "01:43:20.041967 save  5529 110253\n",
      "01:44:19.291195 save  5539 110453\n",
      "01:45:13.838729 save  5549 110653\n",
      "01:45:57.114338 save  5559 110853\n",
      "01:46:51.511354 save  5569 111053\n",
      "01:47:31.985873 save  5579 111251\n",
      "01:48:23.628046 save  5589 111451\n",
      "01:49:11.067334 save  5599 111651\n",
      "01:49:58.870237 save  5609 111851\n",
      "01:50:46.756200 save  5619 112048\n",
      "01:51:25.832055 save  5629 112248\n",
      "01:52:14.936955 save  5639 112448\n",
      "01:53:00.544432 save  5649 112648\n",
      "01:53:44.653453 save  5659 112848\n",
      "01:54:25.540487 save  5669 113047\n",
      "01:55:17.017272 save  5679 113247\n",
      "01:56:14.390279 save  5689 113447\n",
      "01:56:47.564105 save  5699 113644\n",
      "01:57:29.716268 save  5709 113844\n",
      "01:58:14.999088 save  5719 114044\n",
      "01:59:10.032806 save  5729 114244\n",
      "02:00:01.450421 save  5739 114444\n",
      "02:01:03.377726 save  5749 114643\n",
      "02:01:50.379183 save  5759 114843\n",
      "02:02:45.491568 save  5769 115041\n",
      "02:03:29.302819 save  5779 115241\n",
      "02:04:20.687060 save  5789 115440\n",
      "02:05:09.614747 save  5799 115640\n",
      "02:06:00.180115 save  5809 115837\n",
      "02:06:38.997365 save  5819 116037\n",
      "02:07:30.055923 save  5829 116236\n",
      "02:08:24.329826 save  5839 116436\n",
      "02:09:07.945290 save  5849 116635\n",
      "02:09:57.898690 save  5859 116834\n",
      "02:10:42.320315 save  5869 117034\n",
      "02:11:25.824884 save  5879 117233\n",
      "02:12:11.460643 save  5889 117433\n",
      "02:12:57.344296 save  5899 117633\n",
      "02:13:36.408194 save  5909 117832\n",
      "02:14:23.618735 save  5919 118030\n",
      "02:15:11.155960 save  5929 118230\n",
      "02:15:52.328519 save  5939 118430\n",
      "02:16:39.557197 save  5949 118630\n",
      "02:17:27.607816 save  5959 118829\n",
      "02:18:08.200560 save  5969 119028\n",
      "02:18:58.375095 save  5979 119228\n",
      "02:19:53.414701 save  5989 119428\n",
      "02:20:46.124904 save  5999 119628\n",
      "02:21:37.640618 save  6009 119825\n",
      "02:22:22.883676 save  6019 120024\n",
      "02:23:12.043183 save  6029 120224\n",
      "02:24:04.387679 save  6039 120424\n",
      "02:24:55.383062 save  6049 120624\n",
      "02:25:42.590944 save  6059 120824\n",
      "02:26:23.131430 save  6069 121024\n",
      "02:27:13.078464 save  6079 121224\n",
      "02:27:58.259888 save  6089 121424\n",
      "02:28:44.046889 save  6099 121623\n",
      "02:29:28.998627 save  6109 121822\n",
      "02:30:15.256714 save  6119 122022\n",
      "02:31:01.038646 save  6129 122221\n",
      "02:31:47.102010 save  6139 122421\n",
      "02:32:36.831129 save  6149 122618\n",
      "02:33:19.892101 save  6159 122817\n",
      "02:34:06.439931 save  6169 123016\n",
      "02:34:51.430298 save  6179 123216\n",
      "02:35:34.890251 save  6189 123416\n",
      "02:36:22.349643 save  6199 123616\n",
      "02:37:02.479461 save  6209 123816\n",
      "02:37:41.133143 save  6219 124014\n",
      "02:38:29.720492 save  6229 124214\n",
      "02:39:16.099978 save  6239 124414\n",
      "02:39:59.249626 save  6249 124614\n",
      "02:40:45.701106 save  6259 124814\n",
      "02:41:31.604927 save  6269 125012\n",
      "02:42:17.006530 save  6279 125212\n",
      "02:43:07.119991 save  6289 125411\n",
      "02:43:48.090968 save  6299 125611\n",
      "02:44:34.242927 save  6309 125811\n",
      "02:45:28.469730 save  6319 126011\n",
      "02:46:14.252263 save  6329 126211\n",
      "02:46:59.298556 save  6339 126410\n",
      "02:47:54.778807 save  6349 126609\n",
      "02:48:54.154677 save  6359 126808\n",
      "02:49:43.418865 save  6369 127008\n",
      "02:50:18.362873 save  6379 127208\n",
      "02:51:03.202717 save  6389 127408\n",
      "02:51:49.620014 save  6399 127607\n",
      "02:52:23.707182 save  6409 127807\n",
      "02:53:04.106244 save  6419 128005\n",
      "02:53:58.719367 save  6429 128204\n",
      "02:54:43.747931 save  6439 128404\n",
      "02:55:31.056208 save  6449 128604\n",
      "02:56:18.214449 save  6459 128804\n",
      "02:57:07.866952 save  6469 129002\n",
      "02:57:55.810437 save  6479 129202\n",
      "02:58:31.978370 save  6489 129402\n",
      "02:59:11.608519 save  6499 129602\n",
      "03:00:01.598914 save  6509 129802\n",
      "03:00:50.883767 save  6519 130002\n",
      "03:01:38.122899 save  6529 130201\n",
      "03:02:24.591611 save  6539 130401\n",
      "03:03:12.817587 save  6549 130601\n",
      "03:03:54.546194 save  6559 130801\n",
      "03:04:39.441596 save  6569 131001\n",
      "03:05:25.365015 save  6579 131200\n",
      "03:06:11.928859 save  6589 131400\n",
      "03:06:48.948348 save  6599 131600\n",
      "CPU times: user 8h 23min 49s, sys: 1min 42s, total: 8h 25min 32s\n",
      "Wall time: 8h 10min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "\n",
    "batch_size = 5\n",
    "save_every_n_elements = 50\n",
    "translations = []\n",
    "last_stored = -1 #8409\n",
    "\n",
    "# set to the last stored index for recovery\n",
    "if last_stored >= 0:\n",
    "    data_trans = load_dataframe(\"data/german_doctor_reviews_augmented_tmp.parq\")\n",
    "    translations = [row.to_dict() for index, row in data_trans.iterrows()]\n",
    "    print(\"Loaded\", len(translations))\n",
    "\n",
    "for g, df in data_augm.groupby(np.arange(len(data_augm)) // batch_size):\n",
    "    if g > last_stored:\n",
    "        gpu_empty_cache()\n",
    "        back_trans = back_translate_transformers(df[\"text_original\"].to_list())\n",
    "    \n",
    "        i = 0\n",
    "        for index, row in df.iterrows():\n",
    "            \n",
    "            for trans in back_trans[i]:\n",
    "                row_dict = row.to_dict()\n",
    "                row_dict[\"text\"] = trans\n",
    "                translations.append(row_dict)\n",
    "           \n",
    "            i += 1\n",
    "    \n",
    "        if (g + 1) % (save_every_n_elements // batch_size) == 0:\n",
    "            print(datetime.now().time(), \"save \", g, len(translations))\n",
    "        \n",
    "            save_dataframe(pd.DataFrame(translations), \"data/german_doctor_reviews_augmented_tmp.parq\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Skip\", g)\n",
    "              \n",
    "    \n",
    "save_dataframe(pd.DataFrame(translations), \"data/german_doctor_reviews_augmented_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = pd.DataFrame(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>dieser arzt ist das unmöglichste, das ich je i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>dieser arzt ist das unmöglichste, was ich jema...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>dieser arzt ist am wenigsten unmöglich in mein...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "\n",
       "                                                text     label  sentiment  \n",
       "0  dieser arzt ist das unmöglichste, das ich je i...  negative         -1  \n",
       "1  dieser arzt ist das unmöglichste, was ich jema...  negative         -1  \n",
       "2  dieser arzt ist am wenigsten unmöglich in mein...  negative         -1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(save_data, \"data/german_doctor_reviews_augmented_translated_\"+lang_to+\".parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the back translated text and perform normalization of the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/german_doctor_reviews_augmented_translated_es.parq']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob(\"data/german_doctor_reviews*augmented_trans*_[a-z][a-z].parq\")\n",
    "print(files)\n",
    "\n",
    "dataframes = []\n",
    "for file in files:\n",
    "    data_aug = load_dataframe(file)\n",
    "    dataframes.append(data_aug)\n",
    "    \n",
    "data_aug = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131629, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>dieser arzt ist das unmöglichste, das ich je i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>dieser arzt ist das unmöglichste, was ich jema...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>dieser arzt ist am wenigsten unmöglich in mein...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "\n",
       "                                                text     label  sentiment  \n",
       "0  dieser arzt ist das unmöglichste, das ich je i...  negative         -1  \n",
       "1  dieser arzt ist das unmöglichste, was ich jema...  negative         -1  \n",
       "2  dieser arzt ist am wenigsten unmöglich in mein...  negative         -1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhnw.nlp.utils.normalize import tokenize\n",
    "from fhnw.nlp.utils.normalize import tokenize_stem\n",
    "from fhnw.nlp.utils.normalize import tokenize_lemma\n",
    "from fhnw.nlp.utils.normalize import normalize\n",
    "from fhnw.nlp.utils.text import clean_text\n",
    "from fhnw.nlp.utils.text import join_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy>=3.0.5 in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (21.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (57.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (1.0.5)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (4.62.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (0.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (3.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (8.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=3.0.5) (2.4.1)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=3.0.5) (0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy>=3.0.5) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy>=3.0.5) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy>=3.0.5) (3.5.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from pathy>=0.3.5->spacy>=3.0.5) (5.2.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy>=3.0.5) (7.1.2)\n",
      "Requirement already satisfied: contextvars<3,>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.8->spacy>=3.0.5) (2.4)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.5) (2.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.5) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.5) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.5) (2021.5.30)\n",
      "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc<8.1.0,>=8.0.8->spacy>=3.0.5) (0.16)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.6.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2021.8.28)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.62.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-01 00:28:04.728499: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Requirement already satisfied: de-core-news-lg==3.1.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.1.0/de_core_news_lg-3.1.0-py3-none-any.whl#egg=de_core_news_lg==3.1.0 in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from de-core-news-lg==3.1.0) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (57.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (4.62.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (21.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: contextvars<3,>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.8->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.4)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.8->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (0.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc<8.1.0,>=8.0.8->spacy<3.2.0,>=3.1.0->de-core-news-lg==3.1.0) (0.16)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install 'spacy>=3.0.5'\n",
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import spacy\n",
    "!python3 -m spacy download de_core_news_md\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "stemmer = SnowballStemmer(\"german\")\n",
    "empty_stopwords = set()\n",
    "stopwords = set(stopwords.words(\"german\"))\n",
    "n_cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 725 ms, sys: 416 ms, total: 1.14 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make sure we did not introduce maleformated stuff\n",
    "data_aug = data_aug.rename(columns={\"text\": \"text_tmp\"})\n",
    "data_aug = parallelize_dataframe(data_aug, clean_text, n_cores=n_cores, field_read=\"text_tmp\", field_write=\"text\", keep_punctuation=True)\n",
    "data_aug = data_aug.drop(columns=[\"text_tmp\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.1 s, sys: 112 ms, total: 6.21 s\n",
      "Wall time: 6.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.29 s, sys: 656 ms, total: 4.95 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_aug = parallelize_dataframe(data_aug, normalize, n_cores=n_cores, field_read=\"text\", field_write=\"token_clean\", stopwords=empty_stopwords, stemmer=None, lemmanizer=None, lemma_with_ner=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 204 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 s, sys: 1.18 s, total: 32.4 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_aug = parallelize_dataframe(data_aug, join_tokens, n_cores=n_cores, field_read=\"token_clean\", field_write=\"text_clean\", stopwords=empty_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 312 ms, total: 15 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 6.34 s, total: 1min 6s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_aug = parallelize_dataframe(data_aug, normalize, n_cores=n_cores, field_read=\"token_clean\", field_write=\"token_lemma\", stopwords=stopwords, stemmer=None, lemmanizer=nlp, lemma_with_ner=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 308 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 s, sys: 1.59 s, total: 34.6 s\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_aug = parallelize_dataframe(data_aug, normalize, n_cores=n_cores, field_read=\"token_clean\", field_write=\"token_stem\", stopwords=stopwords, stemmer=stemmer, lemmanizer=None, lemma_with_ner=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 384 ms, total: 18.7 s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 1.45 s, total: 35.6 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_aug = parallelize_dataframe(data_aug, normalize, n_cores=n_cores, field_read=\"token_clean\", field_write=\"token_clean_stopwords\", stopwords=stopwords, stemmer=None, lemmanizer=None, lemma_with_ner=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 396 ms, total: 21.1 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized_tmp.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = data_aug[data_aug[\"token_lemma\"].map(len) > 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>dieser arzt ist das unmöglichste, das ich je i...</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, ,, das,...</td>\n",
       "      <td>dieser arzt ist das unmöglichste , das ich je ...</td>\n",
       "      <td>[arzt, unmöglichste, je, leben, triefen, böswi...</td>\n",
       "      <td>[arzt, unmog, ,, je, leb, getroff, ,, boswill,...</td>\n",
       "      <td>[arzt, unmöglichste, ,, je, leben, getroffen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>dieser arzt ist das unmöglichste, was ich jema...</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, ,, was,...</td>\n",
       "      <td>dieser arzt ist das unmöglichste , was ich jem...</td>\n",
       "      <td>[arzt, unmöglichste, jemals, leben, kennen, ve...</td>\n",
       "      <td>[arzt, unmog, ,, jemal, leb, kannt, ,, versaut...</td>\n",
       "      <td>[arzt, unmöglichste, ,, jemals, leben, kannte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>dieser arzt ist am wenigsten unmöglich in mein...</td>\n",
       "      <td>[dieser, arzt, ist, am, wenigsten, unmöglich, ...</td>\n",
       "      <td>dieser arzt ist am wenigsten unmöglich in mein...</td>\n",
       "      <td>[arzt, wenig, unmöglich, leben, finden, unfreu...</td>\n",
       "      <td>[arzt, wenig, unmog, leb, find, ,, unfreund, ,...</td>\n",
       "      <td>[arzt, wenigsten, unmöglich, leben, finden, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating     label  \\\n",
       "0  Dieser Arzt ist das unmöglichste was mir in me...     6.0  negative   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0  negative   \n",
       "2  Dieser Arzt ist das unmöglichste was mir in me...     6.0  negative   \n",
       "\n",
       "   sentiment                                               text  \\\n",
       "0         -1  dieser arzt ist das unmöglichste, das ich je i...   \n",
       "1         -1  dieser arzt ist das unmöglichste, was ich jema...   \n",
       "2         -1  dieser arzt ist am wenigsten unmöglich in mein...   \n",
       "\n",
       "                                         token_clean  \\\n",
       "0  [dieser, arzt, ist, das, unmöglichste, ,, das,...   \n",
       "1  [dieser, arzt, ist, das, unmöglichste, ,, was,...   \n",
       "2  [dieser, arzt, ist, am, wenigsten, unmöglich, ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  dieser arzt ist das unmöglichste , das ich je ...   \n",
       "1  dieser arzt ist das unmöglichste , was ich jem...   \n",
       "2  dieser arzt ist am wenigsten unmöglich in mein...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "0  [arzt, unmöglichste, je, leben, triefen, böswi...   \n",
       "1  [arzt, unmöglichste, jemals, leben, kennen, ve...   \n",
       "2  [arzt, wenig, unmöglich, leben, finden, unfreu...   \n",
       "\n",
       "                                          token_stem  \\\n",
       "0  [arzt, unmog, ,, je, leb, getroff, ,, boswill,...   \n",
       "1  [arzt, unmog, ,, jemal, leb, kannt, ,, versaut...   \n",
       "2  [arzt, wenig, unmog, leb, find, ,, unfreund, ,...   \n",
       "\n",
       "                               token_clean_stopwords  \n",
       "0  [arzt, unmöglichste, ,, je, leben, getroffen, ...  \n",
       "1  [arzt, unmöglichste, ,, jemals, leben, kannte,...  \n",
       "2  [arzt, wenigsten, unmöglich, leben, finden, ,,...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#save_dataframe(data_aug, \"data/german_doctor_reviews_augmented_tokenized.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
