{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" src=\"https://www.fhnw.ch/de/++theme++web16theme/assets/media/img/fachhochschule-nordwestschweiz-fhnw-logo.svg\" alt=\"FHNW Logo\">\n",
    "\n",
    "\n",
    "# Export Trained Classifier\n",
    "\n",
    "by Fabian Märki\n",
    "\n",
    "## Summary\n",
    "The aim of this notebook is to export a trained classifier together with the preprocessing pipeline. This classifier can then be imported and integrated into a production software stack (e.g. as a REST service which makes the classifier accessible from everywhere).\n",
    "\n",
    "### REST Server\n",
    "The code to make the exported classifier available as a service is available from [here](https://github.com/markif/2024_FS_CAS_NLP_LAB_Notebooks/tree/master/rest-server). There is also a README available with further instructions. \n",
    "There is an instance running on *86.119.38.109* which can be accessed by any REST client (e.g. with curl):\n",
    "- `curl -X POST http://86.119.38.109:5000/api/v1/sentiment -H 'Content-Type: application/json' -d '[\"Dies ist ein super Arzt. <br>\", \"Ein schlechter <p> Arzt.\"]'`\n",
    "\n",
    "### INCEpTION\n",
    "[INCEpTION](https://inception-project.github.io/) allows for the integration of recommenders via REST (see [here](https://inception-project.github.io/example-projects/recommender/), [here](https://inception-project.github.io/example-projects/external-recommender/), [here](https://github.com/inception-project/external-recommender-spacy) and [here](https://github.com/inception-project/inception/blob/main/notebooks/external_recommender.ipynb)) which supports annotators by making suggestions for the task at hand (and thus can speedup the annotation process).\n",
    "\n",
    "This notebook does not contain assigments: <font color='red'>Enjoy.</font>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/markif/2024_FS_CAS_NLP_LAB_Notebooks/blob/master/04_b_Export_Trained_Classifier.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install 'fhnw-nlp-utils>=0.8.0,<0.9.0'\n",
    "\n",
    "from fhnw.nlp.utils.storage import download\n",
    "from fhnw.nlp.utils.storage import load_dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS name: posix\n",
      "Platform name: Linux\n",
      "Platform release: 5.19.0-41-generic\n",
      "Python version: 3.8.10\n",
      "CPU cores: 6\n",
      "RAM: 31.12GB total and 18.83GB available\n",
      "Tensorflow version: 2.12.0\n",
      "GPU is available\n",
      "GPU is a NVIDIA GeForce RTX 2070 with Max-Q Design with 8192MiB\n"
     ]
    }
   ],
   "source": [
    "from fhnw.nlp.utils.system import set_log_level\n",
    "from fhnw.nlp.utils.system import system_info\n",
    "\n",
    "set_log_level()\n",
    "print(system_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.13 s, sys: 1.45 s, total: 8.58 s\n",
      "Wall time: 4.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(350087, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "download(\"https://drive.switch.ch/index.php/s/0hE8wO4FbfGIJld/download\", \"data/german_doctor_reviews_tokenized.parq\")\n",
    "data = load_dataframe(\"data/german_doctor_reviews_tokenized.parq\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[ich, bin, franzose, und, bin, seit, ein, paar...</td>\n",
       "      <td>ich bin franzose und bin seit ein paar wochen ...</td>\n",
       "      <td>[franzose, seit, paar, woche, muenchen, zahn, ...</td>\n",
       "      <td>[franzos, seit, paar, woch, muench, ., zahn, s...</td>\n",
       "      <td>[franzose, seit, paar, wochen, muenchen, ., za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>dieser arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglich, leben, je, begegnen, unfreun...</td>\n",
       "      <td>[arzt, unmog, leb, je, begegnet, unfreund, ,, ...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnet, unfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[hatte, akute, beschwerden, am, rücken, ., her...</td>\n",
       "      <td>hatte akute beschwerden am rücken . herr magur...</td>\n",
       "      <td>[akut, beschwerde, rücken, magura, erster, arz...</td>\n",
       "      <td>[akut, beschwerd, ruck, ., magura, erst, arzt,...</td>\n",
       "      <td>[akute, beschwerden, rücken, ., magura, erste,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating   \n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...     2.0  \\\n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...     1.0   \n",
       "\n",
       "                                                text     label  sentiment   \n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...  positive          1  \\\n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...  positive          1   \n",
       "\n",
       "                                         token_clean   \n",
       "0  [ich, bin, franzose, und, bin, seit, ein, paar...  \\\n",
       "1  [dieser, arzt, ist, das, unmöglichste, was, mi...   \n",
       "2  [hatte, akute, beschwerden, am, rücken, ., her...   \n",
       "\n",
       "                                          text_clean   \n",
       "0  ich bin franzose und bin seit ein paar wochen ...  \\\n",
       "1  dieser arzt ist das unmöglichste was mir in me...   \n",
       "2  hatte akute beschwerden am rücken . herr magur...   \n",
       "\n",
       "                                         token_lemma   \n",
       "0  [franzose, seit, paar, woche, muenchen, zahn, ...  \\\n",
       "1  [arzt, unmöglich, leben, je, begegnen, unfreun...   \n",
       "2  [akut, beschwerde, rücken, magura, erster, arz...   \n",
       "\n",
       "                                          token_stem   \n",
       "0  [franzos, seit, paar, woch, muench, ., zahn, s...  \\\n",
       "1  [arzt, unmog, leb, je, begegnet, unfreund, ,, ...   \n",
       "2  [akut, beschwerd, ruck, ., magura, erst, arzt,...   \n",
       "\n",
       "                               token_clean_stopwords  \n",
       "0  [franzose, seit, paar, wochen, muenchen, ., za...  \n",
       "1  [arzt, unmöglichste, leben, je, begegnet, unfr...  \n",
       "2  [akute, beschwerden, rücken, ., magura, erste,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331187, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all neutral sentimens\n",
    "data = data.loc[(data[\"label\"] != \"neutral\")]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we use all data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data[\"token_stem\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier\n",
    "\n",
    "Train the Classifier using the cleaned data and the optimal hyperparameters found through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 200 ms, sys: 24 ms, total: 224 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# serialization in python does not work with lambdas (therefore this function)\n",
    "from fhnw.nlp.utils.processing import identity\n",
    "\n",
    "pipe = Pipeline([\n",
    "         (\"vec\", CountVectorizer(tokenizer=identity, preprocessor=identity, stop_words=None)),\n",
    "         (\"tfidf\", TfidfTransformer()),\n",
    "         (\"clf\", SGDClassifier())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"clf__alpha\": 5.3e-06, \n",
    "    \"tfidf__norm\": \"l2\", \n",
    "    \"tfidf__sublinear_tf\": True, \n",
    "    \"tfidf__use_idf\": True, \n",
    "    \"vec__ngram_range\": (1, 2),\n",
    "    \"vec__max_df\": 0.5, \n",
    "    \"vec__min_df\": 0.0001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 s, sys: 1.52 s, total: 26.7 s\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;,\n",
       "                 CountVectorizer(max_df=0.5, min_df=0.0001, ngram_range=(1, 2),\n",
       "                                 preprocessor=&lt;function identity at 0x7f7bf241c700&gt;,\n",
       "                                 tokenizer=&lt;function identity at 0x7f7bf241c700&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer(sublinear_tf=True)),\n",
       "                (&#x27;clf&#x27;, SGDClassifier(alpha=5.3e-06))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;,\n",
       "                 CountVectorizer(max_df=0.5, min_df=0.0001, ngram_range=(1, 2),\n",
       "                                 preprocessor=&lt;function identity at 0x7f7bf241c700&gt;,\n",
       "                                 tokenizer=&lt;function identity at 0x7f7bf241c700&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer(sublinear_tf=True)),\n",
       "                (&#x27;clf&#x27;, SGDClassifier(alpha=5.3e-06))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.5, min_df=0.0001, ngram_range=(1, 2),\n",
       "                preprocessor=&lt;function identity at 0x7f7bf241c700&gt;,\n",
       "                tokenizer=&lt;function identity at 0x7f7bf241c700&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer(sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=5.3e-06)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 CountVectorizer(max_df=0.5, min_df=0.0001, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function identity at 0x7f7bf241c700>,\n",
       "                                 tokenizer=<function identity at 0x7f7bf241c700>)),\n",
       "                ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
       "                ('clf', SGDClassifier(alpha=5.3e-06))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe.set_params(**best_params)\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 97.7 ms, total: 20.3 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train_pred = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.93     33022\n",
      "    positive       0.99      0.99      0.99    298165\n",
      "\n",
      "    accuracy                           0.99    331187\n",
      "   macro avg       0.97      0.95      0.96    331187\n",
      "weighted avg       0.99      0.99      0.99    331187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_train, y_train_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the preprocessing steps which were originally applied on the data before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#!pip install 'spacy>=3.0.5'\n",
    "\n",
    "#import spacy\n",
    "#!python3 -m spacy download de_core_news_md\n",
    "\n",
    "#nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "!pip install nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words(\"german\"))\n",
    "\n",
    "stemmer = SnowballStemmer(\"german\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the preprocessing functions - these would already be available in a real setting since you used it for preprocessing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhnw.nlp.utils.text import clean_text\n",
    "from fhnw.nlp.utils.normalize import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Preprocessors which can be integrated into a Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhnw.nlp.utils.processing import Preprocessor\n",
    "from fhnw.nlp.utils.processing import provide_computed_df\n",
    "from fhnw.nlp.utils.processing import provide_computed_series_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaner = Preprocessor(clean_text, n_jobs=1, field_read=\"text_original\", field_write=\"text\", finalizer_func=provide_computed_df, keep_punctuation=True)\n",
    "text_normalizer = Preprocessor(normalize, n_jobs=1, field_read=\"text\", field_write=\"token_stem\", finalizer_func=provide_computed_series_as_list, stopwords=stopwords, stemmer=stemmer, lemmanizer=None, lemma_with_ner=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the Preprocessors work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dies ist ein super Arzt. &lt;br&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ein schlechter &lt;p&gt; Arzt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text_original\n",
       "0  Dies ist ein super Arzt. <br>\n",
       "1       Ein schlechter <p> Arzt."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([\"Dies ist ein super Arzt. <br>\", \"Ein schlechter <p> Arzt.\"], columns =[\"text_original\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dies ist ein super Arzt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ein schlechter Arzt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text\n",
       "0  Dies ist ein super Arzt. \n",
       "1       Ein schlechter Arzt."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = text_cleaner.transform(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sup', 'arzt', '.'], ['schlecht', 'arzt', '.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = text_normalizer.transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline with the pretrained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifier = Pipeline([\n",
    "    (\"clean\", text_cleaner),\n",
    "    (\"normalize\", text_normalizer),\n",
    "    (\"vec\", pipe[\"vec\"]),\n",
    "    (\"tfidf\", pipe[\"tfidf\"]),\n",
    "    (\"clf\", pipe[\"clf\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the classifier works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dies ist ein super Arzt. &lt;br&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ein schlechter &lt;p&gt; Arzt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text_original\n",
       "0  Dies ist ein super Arzt. <br>\n",
       "1       Ein schlechter <p> Arzt."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([\"Dies ist ein super Arzt. <br>\", \"Ein schlechter <p> Arzt.\"], columns =[\"text_original\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the complete classifier by serializing it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhnw.nlp.utils.storage import save_pickle\n",
    "from fhnw.nlp.utils.storage import load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.78 s, sys: 140 ms, total: 3.92 s\n",
      "Wall time: 3.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# There are several compression formats available \n",
    "# some result in smaller files (less to download)\n",
    "# while others load/decompress faster (less startup time if loaded from local directory)\n",
    "\n",
    "# gzip compressed file - small files and fast to load - good compromise \n",
    "save_pickle(classifier, \"classifiers/sentiment_classifier.pgz\")\n",
    "\n",
    "# uncompressed file - fastest to load\n",
    "#save_pickle(classifier, \"classifiers/sentiment_classifier.pkl\")\n",
    "\n",
    "# bz2 compressed file - very small files but takes some time to load/decompress (and very long for compression)\n",
    "#save_pickle(classifier, \"classifiers/sentiment_classifier.pbz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the classifier by deserializing it from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 496 ms, sys: 116 ms, total: 612 ms\n",
      "Wall time: 611 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loaded_classifier = load_pickle(\"classifiers/sentiment_classifier.pgz\")\n",
    "#loaded_classifier = load_pickle(\"classifiers/sentiment_classifier.pkl\")\n",
    "#loaded_classifier = load_pickle(\"classifiers/sentiment_classifier.pbz2\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if it still works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_classifier.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel and try if it still works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhnw.nlp.utils.storage import load_pickle\n",
    "\n",
    "loaded_classifier2 = load_pickle(\"classifiers/sentiment_classifier.pgz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame([\"Dies ist ein super Arzt. <br>\", \"Ein schlechter <p> Arzt.\"], columns =[\"text_original\"])\n",
    "\n",
    "loaded_classifier2.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
